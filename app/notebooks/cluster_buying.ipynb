{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import time\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "# returns_and_market_cap contains monthly returns and market cap data per company\n",
    "returns_and_market_cap = pd.read_csv(f\"{DATA_DIR}/returns_market_cap.csv\")\n",
    "\n",
    "# ndt contains non-derivative transaction data (e.g., insider trades)\n",
    "ndt = pd.read_csv(f\"{DATA_DIR}/ndt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-derivative transaction data:\n",
      "| ACCESSION_NUMBER     | TRANS_DATE   | TRANS_CODE   |   EQUITY_SWAP_INVOLVED |   TRANS_SHARES |   TRANS_PRICEPERSHARE | TRANS_ACQUIRED_DISP_CD   |   SHRS_OWND_FOLWNG_TRANS | DIRECT_INDIRECT_OWNERSHIP   |   COMPANY_ID | RPTOWNERNAME     | RPTOWNER_RELATIONSHIP   | RPTOWNER_TITLE         |\n",
      "|:---------------------|:-------------|:-------------|-----------------------:|---------------:|----------------------:|:-------------------------|-------------------------:|:----------------------------|-------------:|:-----------------|:------------------------|:-----------------------|\n",
      "| 0000076605-17-000121 | 2017-09-27   | S            |                      0 |          10000 |                 83.16 | D                        |          15000           | D                           |       295249 | Cleveland Todd M | Director,Officer        | CEO                    |\n",
      "| 0001140361-17-037031 | 2017-09-27   | F            |                      0 |          28833 |                 16.46 | D                        |              3.36052e+06 | D                           |     54070696 | Olson Michael    | Officer                 | Chief Strategy Officer |\n",
      "| 0001140361-17-037030 | 2017-04-27   | M            |                      0 |          11875 |                  0    | A                        |              3.36052e+06 | D                           |     54070696 | Olson Michael    | Officer                 | Chief Strategy Officer |\n",
      "| 0001140361-17-037030 | 2017-09-15   | M            |                      0 |           9063 |                  0    | A                        |              3.36052e+06 | D                           |     54070696 | Olson Michael    | Officer                 | Chief Strategy Officer |\n",
      "| 0001140361-17-037030 | 2017-09-15   | M            |                      0 |           8333 |                  0    | A                        |              3.36052e+06 | D                           |     54070696 | Olson Michael    | Officer                 | Chief Strategy Officer |\n",
      "\n",
      "Returns and market cap data:\n",
      "| MONTH_END   |   COMPANY_ID |   RETURN_LEAD_1_MONTHS |   RETURN_LEAD_3_MONTHS |   RETURN_LEAD_12_MONTHS |   MARKET_CAP_USD |\n",
      "|:------------|-------------:|-----------------------:|-----------------------:|------------------------:|-----------------:|\n",
      "| 1994-07-31  |        18511 |             0.106531   |              0.109966  |                0.375126 |          2616.76 |\n",
      "| 1994-08-31  |        18511 |             0.0139749  |              0.043478  |                0.255416 |          2885.57 |\n",
      "| 1994-09-30  |        18511 |            -0.0107207  |              0.0316986 |                0.261565 |          3001.81 |\n",
      "| 1994-10-31  |        18511 |             0.0402486  |              0.083469  |                0.292618 |          3078.85 |\n",
      "| 1994-11-30  |        18511 |             0.00252853 |              0.0355451 |                0.279064 |          3069.56 |\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-derivative transaction data:\")\n",
    "print(ndt.head().to_markdown(index=False))\n",
    "print()\n",
    "print(\"Returns and market cap data:\")\n",
    "print(returns_and_market_cap.head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Data Preparation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Dropped 15 rows with invalid TRANS_DATE.\n",
      "Sample of trades data after preparation:\n",
      "| ACCESSION_NUMBER     | TRANS_DATE          | TRANS_CODE   |   EQUITY_SWAP_INVOLVED |   TRANS_SHARES |   TRANS_PRICEPERSHARE | TRANS_ACQUIRED_DISP_CD   |   SHRS_OWND_FOLWNG_TRANS | DIRECT_INDIRECT_OWNERSHIP   |   COMPANY_ID | RPTOWNERNAME   | RPTOWNER_RELATIONSHIP   | RPTOWNER_TITLE                 | month_end           |      trade_value |\n",
      "|:---------------------|:--------------------|:-------------|-----------------------:|---------------:|----------------------:|:-------------------------|-------------------------:|:----------------------------|-------------:|:---------------|:------------------------|:-------------------------------|:--------------------|-----------------:|\n",
      "| 0000001750-06-000002 | 2006-01-04 00:00:00 | S            |                      0 |         144360 |                 24.64 | D                        |                  6876.17 | D                           |       168154 | STORCH DAVID P | Director,Officer        | Chairman, Pres., CEO, Director | 2006-01-31 00:00:00 |      3.55703e+06 |\n",
      "| 0000001750-06-000054 | 2006-03-28 00:00:00 | S            |                      0 |          66200 |                 27.46 | D                        |                 18810    | D                           |       168154 | STORCH DAVID P | Director,Officer        | President, CEO & Director      | 2006-03-31 00:00:00 |      1.81785e+06 |\n",
      "| 0000001750-06-000056 | 2006-03-29 00:00:00 | S            |                      0 |         290912 |                 27.47 | D                        |                  6876.17 | D                           |       168154 | STORCH DAVID P | Director,Officer        | President, CEO & Director      | 2006-03-31 00:00:00 |      7.99135e+06 |\n",
      "| 0000001750-06-000060 | 2006-03-31 00:00:00 | S            |                      0 |          50000 |                 28.4  | D                        |                 18810    | D                           |       168154 | STORCH DAVID P | Director,Officer        | President, CEO & Director      | 2006-03-31 00:00:00 |      1.42e+06    |\n",
      "| 0000001750-06-000062 | 2006-04-03 00:00:00 | S            |                      0 |          24010 |                 29.14 | D                        |                 18810    | D                           |       168154 | STORCH DAVID P | Director,Officer        | President, CEO & Director      | 2006-04-30 00:00:00 | 699651           |\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime for consistent handling\n",
    "# MONTH_END in returns_and_market_cap is the end-of-month date for returns/market cap\n",
    "returns_and_market_cap['MONTH_END'] = pd.to_datetime(returns_and_market_cap['MONTH_END'])\n",
    "\n",
    "# TRANS_DATE in ndt is the transaction date; use errors='coerce' to handle invalid dates\n",
    "ndt['TRANS_DATE'] = pd.to_datetime(ndt['TRANS_DATE'], errors='coerce')\n",
    "\n",
    "# Create a month-end column in ndt by rounding transaction dates to the nearest month end\n",
    "ndt['month_end'] = ndt['TRANS_DATE'] + MonthEnd(0)\n",
    "\n",
    "# Check for and drop rows with invalid transaction dates (NaT)\n",
    "invalid_dates = ndt['TRANS_DATE'].isna().sum()\n",
    "if invalid_dates > 0:\n",
    "    print(f\"Warning: Dropped {invalid_dates} rows with invalid TRANS_DATE.\")\n",
    "    ndt = ndt.dropna(subset=['TRANS_DATE'])\n",
    "\n",
    "# Filter ndt to include only buy ('P') and sell ('S') transactions\n",
    "trades = ndt[ndt['TRANS_CODE'].isin(['P', 'S'])].copy()\n",
    "\n",
    "# Collapse duplicate rows so each ACCESSION_NUMBER is one trade\n",
    "trades = trades.groupby('ACCESSION_NUMBER', as_index=False).agg({\n",
    "    'TRANS_DATE': 'first',\n",
    "    'TRANS_CODE': 'first',\n",
    "    'EQUITY_SWAP_INVOLVED': 'first',\n",
    "    'TRANS_SHARES': 'sum',\n",
    "    'TRANS_PRICEPERSHARE': 'first',\n",
    "    'TRANS_ACQUIRED_DISP_CD': 'first',\n",
    "    'SHRS_OWND_FOLWNG_TRANS': 'first',\n",
    "    'DIRECT_INDIRECT_OWNERSHIP': 'first',\n",
    "    'COMPANY_ID': 'first',\n",
    "    'RPTOWNERNAME': 'first',\n",
    "    'RPTOWNER_RELATIONSHIP': 'first',\n",
    "    'RPTOWNER_TITLE': 'first',\n",
    "    'month_end': 'first'\n",
    "})\n",
    "\n",
    "# Calculate the dollar value of each trade (shares * price per share)\n",
    "trades['trade_value'] = trades['TRANS_SHARES'] * trades['TRANS_PRICEPERSHARE']\n",
    "\n",
    "print(\"Sample of trades data after preparation:\")\n",
    "print(trades.head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Market Returns Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of market_return_1m market returns:\n",
      "| MONTH_END           |   market_return_1m |\n",
      "|:--------------------|-------------------:|\n",
      "| 1962-01-31 00:00:00 |          0.0886072 |\n",
      "| 1962-02-28 00:00:00 |         -0.0697672 |\n",
      "| 1962-03-31 00:00:00 |          0.0249994 |\n",
      "| 1962-04-30 00:00:00 |         -0.414634  |\n",
      "| 1962-05-31 00:00:00 |          0.0520832 |\n",
      "Sample of market_return_3m market returns:\n",
      "| MONTH_END           |   market_return_3m |\n",
      "|:--------------------|-------------------:|\n",
      "| 1962-01-31 00:00:00 |           0.037974 |\n",
      "| 1962-02-28 00:00:00 |          -0.44186  |\n",
      "| 1962-03-31 00:00:00 |          -0.36875  |\n",
      "| 1962-04-30 00:00:00 |          -0.256097 |\n",
      "| 1962-05-31 00:00:00 |           0.375    |\n",
      "Sample of market_return_12m market returns:\n",
      "| MONTH_END           |   market_return_12m |\n",
      "|:--------------------|--------------------:|\n",
      "| 1962-01-31 00:00:00 |           -0.319621 |\n",
      "| 1962-02-28 00:00:00 |           -0.331395 |\n",
      "| 1962-03-31 00:00:00 |           -0.234376 |\n",
      "| 1962-04-30 00:00:00 |           -0.14939  |\n",
      "| 1962-05-31 00:00:00 |            0.510417 |\n"
     ]
    }
   ],
   "source": [
    "# Compute total market capitalization per month for weighting returns\n",
    "# Sum MARKET_CAP_USD across all companies for each MONTH_END\n",
    "total_cap = returns_and_market_cap.groupby('MONTH_END')['MARKET_CAP_USD'].sum().rename('total_cap')\n",
    "\n",
    "# Join total_cap back to returns_and_market_cap for weight calculation\n",
    "returns_and_market_cap = returns_and_market_cap.join(total_cap, on='MONTH_END')\n",
    "\n",
    "# Calculate each company's weight as its market cap divided by total market cap\n",
    "returns_and_market_cap['weight'] = returns_and_market_cap['MARKET_CAP_USD'] / returns_and_market_cap['total_cap']\n",
    "\n",
    "# Initialize a dictionary to store market returns for different horizons (1, 3, 12 months)\n",
    "market_returns = {}\n",
    "\n",
    "# Compute weighted market returns for each horizon\n",
    "# For each month, multiply individual company returns by their weights and sum\n",
    "for horizon in ['1', '3', '12']:\n",
    "    market_returns[f'market_return_{horizon}m'] = returns_and_market_cap.groupby('MONTH_END').apply(\n",
    "        lambda df: np.sum(df[f'RETURN_LEAD_{horizon}_MONTHS'] * df['weight']),\n",
    "        include_groups=False  # Avoid including group keys in the apply function\n",
    "    ).reset_index(name=f'market_return_{horizon}m')\n",
    "\n",
    "for horizon in ['1', '3', '12']:\n",
    "    print(f\"Sample of market_return_{horizon}m market returns:\")\n",
    "    print(market_returns[f'market_return_{horizon}m'].head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Merging Trades with Returns Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of merged data with excess returns:\n",
      "|   COMPANY_ID | month_end           | TRANS_CODE   |   excess_return_1m |   excess_return_3m |   excess_return_12m |\n",
      "|-------------:|:--------------------|:-------------|-------------------:|-------------------:|--------------------:|\n",
      "|       168154 | 2006-01-31 00:00:00 | S            |          0.0584863 |          0.0745878 |           0.0870041 |\n",
      "|       168154 | 2006-03-31 00:00:00 | S            |         -0.0752978 |         -0.193422  |          -0.165043  |\n",
      "|       168154 | 2006-03-31 00:00:00 | S            |         -0.0752978 |         -0.193422  |          -0.165043  |\n",
      "|       168154 | 2006-03-31 00:00:00 | S            |         -0.0752978 |         -0.193422  |          -0.165043  |\n",
      "|       168154 | 2006-04-30 00:00:00 | S            |         -0.0544755 |         -0.0779137 |          -0.0112499 |\n"
     ]
    }
   ],
   "source": [
    "# Merge trades with returns_and_market_cap to align trade data with returns and market cap\n",
    "# Use left join to keep all trades, even if no matching returns data exists\n",
    "merged = trades.merge(returns_and_market_cap, \n",
    "                      left_on=['COMPANY_ID', 'month_end'], \n",
    "                      right_on=['COMPANY_ID', 'MONTH_END'], \n",
    "                      how='left').drop(columns='MONTH_END')  # Drop redundant MONTH_END column\n",
    "\n",
    "# Merge in the precomputed market returns for each horizon\n",
    "for horizon, df in market_returns.items():\n",
    "    merged = merged.merge(df, \n",
    "                          left_on='month_end', \n",
    "                          right_on='MONTH_END', \n",
    "                          how='left').drop(columns='MONTH_END')\n",
    "\n",
    "# Calculate excess returns for each horizon (company return - market return)\n",
    "for horizon in ['1', '3', '12']:\n",
    "    merged[f'excess_return_{horizon}m'] = merged[f'RETURN_LEAD_{horizon}_MONTHS'] - merged[f'market_return_{horizon}m']\n",
    "\n",
    "print(\"Sample of merged data with excess returns:\")\n",
    "print(merged[['COMPANY_ID', 'month_end', 'TRANS_CODE', 'excess_return_1m', 'excess_return_3m', 'excess_return_12m']].head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: Cluster Buying and Quintile Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster buying measures computed in 0.2828 seconds\n",
      "Sample of merged data with cluster buying measures:\n",
      "|   COMPANY_ID | month_end           |   num_buyers | cluster_buy   |   cluster_quintile |\n",
      "|-------------:|:--------------------|-------------:|:--------------|-------------------:|\n",
      "|       168154 | 2006-01-31 00:00:00 |            0 | False         |                  0 |\n",
      "|       168154 | 2006-03-31 00:00:00 |            0 | False         |                  0 |\n",
      "|       168154 | 2006-03-31 00:00:00 |            0 | False         |                  0 |\n",
      "|       168154 | 2006-03-31 00:00:00 |            0 | False         |                  0 |\n",
      "|       168154 | 2006-04-30 00:00:00 |            0 | False         |                  0 |\n",
      "cluster_buy flag: True indicates 2 or more unique insider buyers in that company/month.\n",
      "cluster_quintile: 0 = no buys; 1-5 indicate increasing intensity of cluster buying among months with buyers.\n"
     ]
    }
   ],
   "source": [
    "# Start timing this section for performance tracking\n",
    "start = time.perf_counter()\n",
    "\n",
    "# Identify only buy transactions (TRANS_CODE 'P')\n",
    "buy_trades = trades[trades['TRANS_CODE'] == 'P'].copy()\n",
    "\n",
    "# Count the number of unique insiders (using RPTOWNERNAME) buying in each company/month\n",
    "cluster_counts = buy_trades.groupby(['COMPANY_ID', 'month_end'])['RPTOWNERNAME'] \\\n",
    "    .nunique() \\\n",
    "    .reset_index(name='num_buyers')\n",
    "\n",
    "# Merge the cluster counts back into the merged DataFrame (fill missing values with 0)\n",
    "merged = merged.merge(cluster_counts, on=['COMPANY_ID', 'month_end'], how='left')\n",
    "merged['num_buyers'] = merged['num_buyers'].fillna(0)\n",
    "\n",
    "# Flag cluster buying: a company-month is considered to have cluster buying if there are 2 or more unique buyers\n",
    "merged['cluster_buy'] = merged['num_buyers'] > 1\n",
    "\n",
    "# For a more granular measure, assign quintiles based on num_buyers within each month_end.\n",
    "# For months with at least one buyer, this ranks the intensity of cluster buying.\n",
    "def assign_quintiles(x):\n",
    "    # Only quintile months with at least one buyer\n",
    "    positives = x[x > 0]\n",
    "    quintiles = pd.qcut(positives, 5, labels=False, duplicates='drop') + 1\n",
    "    result = pd.Series(0, index=x.index)            # default 0 for no-buy\n",
    "    result.loc[positives.index] = quintiles\n",
    "    return result\n",
    "\n",
    "merged['cluster_quintile'] = merged.groupby('month_end')['num_buyers'] \\\n",
    "    .transform(assign_quintiles)\n",
    "\n",
    "# For months with no buyers, cluster_quintile might be missing; fill those with 0 (or another indicator)\n",
    "merged['cluster_quintile'] = merged['cluster_quintile'].fillna(0)\n",
    "\n",
    "print(f\"Cluster buying measures computed in {time.perf_counter() - start:.4f} seconds\")\n",
    "print(\"Sample of merged data with cluster buying measures:\")\n",
    "print(merged[['COMPANY_ID', 'month_end', 'num_buyers', 'cluster_buy', 'cluster_quintile']].head().to_markdown(index=False))\n",
    "\n",
    "print(\n",
    "    \"cluster_buy flag: True indicates 2 or more unique insider buyers in that company/month.\\n\"\n",
    "    \"cluster_quintile: 0 = no buys; 1-5 indicate increasing intensity of cluster buying among months with buyers.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2: Cluster Selling and Quintile Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster selling measures computed in 0.3857 seconds\n",
      "Sample of merged data with cluster selling measures:\n",
      "|   COMPANY_ID | month_end           |   num_sellers | cluster_sell   |   cluster_sell_quintile |\n",
      "|-------------:|:--------------------|--------------:|:---------------|------------------------:|\n",
      "|       168154 | 2006-01-31 00:00:00 |             1 | False          |                       1 |\n",
      "|       168154 | 2006-03-31 00:00:00 |             1 | False          |                       1 |\n",
      "|       168154 | 2006-03-31 00:00:00 |             1 | False          |                       1 |\n",
      "|       168154 | 2006-03-31 00:00:00 |             1 | False          |                       1 |\n",
      "|       168154 | 2006-04-30 00:00:00 |             1 | False          |                       1 |\n",
      "cluster_sell flag: True indicates ≥2 unique insider sellers in that company/month.\n",
      "cluster_sell_quintile: 0 = no sells; 1–5 indicate increasing intensity of cluster selling among months with sellers.\n"
     ]
    }
   ],
   "source": [
    "# Start timing this section for performance tracking\n",
    "start = time.perf_counter()\n",
    "\n",
    "# Identify only sell transactions (TRANS_CODE 'S')\n",
    "sell_trades = trades[trades['TRANS_CODE'] == 'S'].copy()\n",
    "\n",
    "# Count the number of unique insiders (using RPTOWNERNAME) selling in each company/month\n",
    "cluster_sell_counts = sell_trades.groupby(['COMPANY_ID', 'month_end'])['RPTOWNERNAME'] \\\n",
    "    .nunique() \\\n",
    "    .reset_index(name='num_sellers')\n",
    "\n",
    "# Merge the cluster sell counts back into the merged DataFrame (fill missing values with 0)\n",
    "merged = merged.merge(cluster_sell_counts, on=['COMPANY_ID', 'month_end'], how='left')\n",
    "merged['num_sellers'] = merged['num_sellers'].fillna(0)\n",
    "\n",
    "# Flag cluster selling: a company-month is considered to have cluster selling if there are 2 or more unique sellers\n",
    "merged['cluster_sell'] = merged['num_sellers'] > 1\n",
    "\n",
    "# Assign quintiles based on num_sellers within each month_end\n",
    "def assign_sell_quintiles(x):\n",
    "    positives = x[x > 0]\n",
    "    quintiles = pd.qcut(positives, 5, labels=False, duplicates='drop') + 1\n",
    "    result = pd.Series(0, index=x.index)\n",
    "    result.loc[positives.index] = quintiles\n",
    "    return result\n",
    "\n",
    "merged['cluster_sell_quintile'] = merged.groupby('month_end')['num_sellers'] \\\n",
    "    .transform(assign_sell_quintiles)\n",
    "\n",
    "# Fill missing cluster_sell_quintile (months with zero sellers) with 0\n",
    "merged['cluster_sell_quintile'] = merged['cluster_sell_quintile'].fillna(0)\n",
    "\n",
    "print(f\"Cluster selling measures computed in {time.perf_counter() - start:.4f} seconds\")\n",
    "print(\"Sample of merged data with cluster selling measures:\")\n",
    "print(merged[['COMPANY_ID', 'month_end', 'num_sellers', 'cluster_sell', 'cluster_sell_quintile']].head().to_markdown(index=False))\n",
    "\n",
    "print(\n",
    "    \"cluster_sell flag: True indicates ≥2 unique insider sellers in that company/month.\\n\"\n",
    "    \"cluster_sell_quintile: 0 = no sells; 1–5 indicate increasing intensity of cluster selling among months with sellers.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse to one row per firm-month so each observation counts once\n",
    "unique_merged = merged.drop_duplicates(subset=['COMPANY_ID','month_end'])[\n",
    "    ['COMPANY_ID','month_end','cluster_quintile',\n",
    "     'excess_return_1m','excess_return_3m','excess_return_12m']\n",
    "].copy()\n",
    "\n",
    "unique_sell = merged.drop_duplicates(subset=['COMPANY_ID','month_end'])[\n",
    "    ['COMPANY_ID','month_end','cluster_sell_quintile',\n",
    "     'excess_return_1m','excess_return_3m','excess_return_12m']\n",
    "].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1: Performance Analysis of Cluster Buying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 196492 rows due to missing excess returns.\n",
      "Performance by cluster buying quintile:\n",
      "|    |   cluster_quintile |   ann_excess_1m |   ann_excess_3m |   ann_excess_12m |   hit_rate_1m |   hit_rate_3m |   hit_rate_2m |   count_1m |   count_3m |   count_12m |\n",
      "|---:|-------------------:|----------------:|----------------:|-----------------:|--------------:|--------------:|--------------:|-----------:|-----------:|------------:|\n",
      "|  0 |                  0 |       0.0279873 |       0.0839434 |        0.30845   |      0.491308 |      0.483676 |      0.463382 |        301 |        301 |         298 |\n",
      "|  1 |                  1 |       0.0572494 |       0.090943  |        0.395064  |      0.483788 |      0.475536 |      0.457609 |        230 |        230 |         227 |\n",
      "|  2 |                  2 |      -0.0265636 |       0.0236758 |       -0.0854162 |      0.472915 |      0.488867 |      0.473912 |        226 |        226 |         223 |\n",
      "|  3 |                  3 |       0.0259867 |      -0.0333334 |       -0.0979833 |      0.467054 |      0.461886 |      0.481266 |        193 |        193 |         192 |\n",
      "|  4 |                  4 |       0.437424  |      -0.187866  |       -0.618134  |      0.509615 |      0.375    |      0.442308 |         28 |         28 |          28 |\n",
      "\n",
      "Notes:\n",
      "- Annualized returns use geometric compounding; non-positive returns fall back to arithmetic mean * 12.\n",
      "- Hit rate measures the fraction of months where excess return > 0.\n",
      "- Counts show the number of monthly observations per cluster buying quintile for each horizon.\n"
     ]
    }
   ],
   "source": [
    "# Filter to rows with at least one non-null excess return (more permissive than all three)\n",
    "valid_cluster = unique_merged.dropna(subset=[f'excess_return_{h}m' for h in ['1','3','12']], how='all').copy()\n",
    "print(f\"Dropped {len(merged) - len(valid_cluster)} rows due to missing excess returns.\")\n",
    "\n",
    "# Compute monthly average excess returns by cluster buying quintile\n",
    "monthly_cluster = valid_cluster.groupby(['month_end', 'cluster_quintile'])[\n",
    "    [f'excess_return_{h}m' for h in ['1', '3', '12']]\n",
    "].mean().reset_index()\n",
    "\n",
    "# Define a function to annualize returns\n",
    "# Uses geometric compounding; falls back to arithmetic mean if cumulative return is non-positive\n",
    "def annualize(series):\n",
    "    series = series.dropna()  # Drop NaNs before calculation\n",
    "    cum_return = (1 + series).prod()  # Cumulative return\n",
    "    n = len(series)  # Number of periods\n",
    "    # If positive cumulative return and data exists, annualize geometrically\n",
    "    if cum_return > 0 and n > 0:\n",
    "        return cum_return**(12/n) - 1\n",
    "    # Otherwise, use arithmetic mean annualized (or NaN if no data)\n",
    "    return series.mean() * 12 if n > 0 else np.nan\n",
    "\n",
    "# Calculate annualized excess returns per cluster buying quintile\n",
    "agg_cluster = monthly_cluster.groupby('cluster_quintile').agg(**{\n",
    "    f'ann_excess_{h}m': (f'excess_return_{h}m', annualize) for h in ['1', '3', '12']\n",
    "}).reset_index()\n",
    "\n",
    "# Count non-null monthly observations per cluster buying quintile for each horizon\n",
    "counts_cluster = monthly_cluster.groupby('cluster_quintile').agg(**{\n",
    "    f'count_{h}m': (f'excess_return_{h}m', 'count') for h in ['1', '3', '12']\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate hit rate: proportion of months where excess return > 0 (positive performance)\n",
    "hit_cluster = valid_cluster.groupby('month_end').apply(\n",
    "    lambda df: df.assign(**{f'beat_mean_{h}m': df[f'excess_return_{h}m'] > 0 for h in ['1', '3', '12']}),\n",
    "    include_groups=False  # Exclude group keys from apply\n",
    ").groupby('cluster_quintile')[\n",
    "    [f'beat_mean_{h}m' for h in ['1', '3', '12']]\n",
    "].mean().reset_index().rename(\n",
    "    columns=lambda c: f'hit_rate_{c[-2:]}' if 'beat' in c else c\n",
    ")\n",
    "\n",
    "# Combine all performance metrics into one DataFrame\n",
    "performance_cluster = agg_cluster.merge(hit_cluster, on='cluster_quintile').merge(counts_cluster, on='cluster_quintile').sort_values('cluster_quintile')\n",
    "\n",
    "print(\"Performance by cluster buying quintile:\")\n",
    "print(performance_cluster.to_markdown())\n",
    "\n",
    "print(\"\\nNotes:\")\n",
    "print(\"- Annualized returns use geometric compounding; non-positive returns fall back to arithmetic mean * 12.\")\n",
    "print(\"- Hit rate measures the fraction of months where excess return > 0.\")\n",
    "print(\"- Counts show the number of monthly observations per cluster buying quintile for each horizon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2: Performance Analysis of Cluster Selling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 196492 rows due to missing excess returns.\n",
      "Performance by cluster selling quintile:\n",
      "|   cluster_sell_quintile |   ann_excess_1m |   ann_excess_3m |   ann_excess_12m |   hit_rate_1m |   hit_rate_3m |   hit_rate_2m |   count_1m |   count_3m |   count_12m |\n",
      "|------------------------:|----------------:|----------------:|-----------------:|--------------:|--------------:|--------------:|-----------:|-----------:|------------:|\n",
      "|                       0 |      0.0685431  |      0.155863   |        0.566196  |      0.481856 |      0.476842 |      0.461046 |        301 |        301 |         298 |\n",
      "|                       1 |      0.00892506 |      0.00893337 |        0.0923987 |      0.489808 |      0.482416 |      0.45983  |        227 |        227 |         224 |\n",
      "|                       2 |      0.00370978 |      0.0272323  |        0.207138  |      0.492205 |      0.489394 |      0.483772 |        222 |        222 |         219 |\n",
      "|                       3 |     -0.0297065  |     -0.0154824  |        0.153954  |      0.500668 |      0.47707  |      0.47106  |        206 |        206 |         203 |\n",
      "|                       4 |      0.141569   |      0.0849048  |        0.12505   |      0.568835 |      0.506808 |      0.521936 |         24 |         24 |          24 |\n",
      "\n",
      "Notes:\n",
      "- Annualized returns use geometric compounding; non-positive returns fall back to arithmetic mean * 12.\n",
      "- Hit rate measures the fraction of months where excess return > 0.\n",
      "- Counts show the number of monthly observations per cluster selling quintile for each horizon.\n"
     ]
    }
   ],
   "source": [
    "# Filter to rows with at least one non-null excess return (more permissive than all three)\n",
    "valid_cluster_sell = unique_sell.dropna(subset=[f'excess_return_{h}m' for h in ['1','3','12']], how='all').copy()\n",
    "\n",
    "print(f\"Dropped {len(merged) - len(valid_cluster_sell)} rows due to missing excess returns.\")\n",
    "\n",
    "# Compute monthly average excess returns by cluster selling quintile\n",
    "monthly_cluster_sell = valid_cluster_sell.groupby(['month_end', 'cluster_sell_quintile'])[\n",
    "    [f'excess_return_{h}m' for h in ['1', '3', '12']]\n",
    "].mean().reset_index()\n",
    "\n",
    "# Calculate annualized excess returns per cluster selling quintile\n",
    "agg_cluster_sell = monthly_cluster_sell.groupby('cluster_sell_quintile').agg(**{\n",
    "    f'ann_excess_{h}m': (f'excess_return_{h}m', annualize) for h in ['1', '3', '12']\n",
    "}).reset_index()\n",
    "\n",
    "# Count non-null monthly observations per cluster selling quintile for each horizon\n",
    "counts_cluster_sell = monthly_cluster_sell.groupby('cluster_sell_quintile').agg(**{\n",
    "    f'count_{h}m': (f'excess_return_{h}m', 'count') for h in ['1', '3', '12']\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate hit rate: proportion of months where excess return > 0 (positive performance)\n",
    "hit_cluster_sell = valid_cluster_sell.groupby('month_end').apply(\n",
    "    lambda df: df.assign(**{f'beat_mean_{h}m': df[f'excess_return_{h}m'] > 0 for h in ['1', '3', '12']}),\n",
    "    include_groups=False\n",
    ").groupby('cluster_sell_quintile')[\n",
    "    [f'beat_mean_{h}m' for h in ['1', '3', '12']]\n",
    "].mean().reset_index().rename(\n",
    "    columns=lambda c: f'hit_rate_{c[-2:]}' if 'beat' in c else c\n",
    ")\n",
    "\n",
    "# Combine all performance metrics into one DataFrame\n",
    "performance_cluster_sell = (\n",
    "    agg_cluster_sell\n",
    "    .merge(hit_cluster_sell, on='cluster_sell_quintile')\n",
    "    .merge(counts_cluster_sell, on='cluster_sell_quintile')\n",
    "    .sort_values('cluster_sell_quintile')\n",
    ")\n",
    "\n",
    "print(\"Performance by cluster selling quintile:\")\n",
    "print(performance_cluster_sell.to_markdown(index=False))\n",
    "\n",
    "print(\"\\nNotes:\")\n",
    "print(\"- Annualized returns use geometric compounding; non-positive returns fall back to arithmetic mean * 12.\")\n",
    "print(\"- Hit rate measures the fraction of months where excess return > 0.\")\n",
    "print(\"- Counts show the number of monthly observations per cluster selling quintile for each horizon.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
